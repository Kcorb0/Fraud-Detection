{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a6983c",
   "metadata": {},
   "source": [
    "# Assignment 2: Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a1162",
   "metadata": {},
   "source": [
    "Author: Josh NM Blackmore <br>\n",
    "StID: 201776628"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8cbe8",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "\n",
    "<p>An insurance company plans to utilise their historic insurance fraud dataset to predict the likelihood or the level of risk a customer poses. You can find the dataset above. Referring genuine claims cause customer stress and directly leads to customer loss, costing the company money (assume that any referred non-fraud case will lead to losing that customer). While obviously, fraud claims cost the company as well. Their main requirement is to use an unbiased predictive model capable of flagging and referring potential fraud cases for further investigation with a balanced error rate of 5%.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0fdb1",
   "metadata": {},
   "source": [
    "## 1 Aims, Objectives & Plan\n",
    "### 1.1 Aims & Objectives\n",
    "This projects primary objective is to analyse a medium sized dataset containing insurance claims from an insurance company with the goal of identifying potential fraudulant claims. The project requires a minumum of two techniques to provide predictions or valuable insights.\n",
    "\n",
    "Provided datasets will be pre-processed with various techniques and the reasoning behind certain decisions. \n",
    "\n",
    "Secondly, a technical report which consists of a narration around the analysis conducted for the project. This will be a jupyter notebook document containing the key procedures taken for each step such as justifying choices made in pre-processing, the models solutions, various visualisations of the analysis and testing with performance metrics such as F1, recall, confusion matrix etc.\n",
    "\n",
    "### 1.2 Plan\n",
    "- Gantt Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d478258",
   "metadata": {},
   "source": [
    "## 2 Understanding the Case Study\n",
    "### 2.1 Case Study Analysis\n",
    "#### 2.1.1 Predicting a Customers Level of Risk\n",
    "Each row of the datasets provide information for an individual customers claim with labels depicting if the claim was fraudulant or legitimate. The client needs to know what level of risk future clients pose for future cases, using historical data.\n",
    "\n",
    "#### 2.1.2 Cost of Fraudulant Cases for Customers and Company\n",
    "Cases provided contain various cost factors such as property claim, injury claims etc. Part of the case study specifies the need to highlight the cost risk for fraudulant cases company and customer alike, the case study specifies the risk of losing customers due to cost. \n",
    "\n",
    "#### 2.1.3 Unbiased Prediction Model to Flag Fraudulant Cases\n",
    "\n",
    "\n",
    "#### 2.1.4 Accuracy and Error Rate of the Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab0b54",
   "metadata": {},
   "source": [
    "## 3 Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041809a",
   "metadata": {},
   "source": [
    "#### Importing Initial Permitted Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e62c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2926c14",
   "metadata": {},
   "source": [
    "#### Loading the Datasets into Pandas Dataframes for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c802cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_csv = \"./Data/archive/TrainData/TrainData/Train_Claim.csv\"\n",
    "customers_withoutTarget_csv = \"./Data/archive/TrainData/TrainData/Traindata_withoutTarget.csv\"\n",
    "customers_withTarget_csv = \"./Data/archive/TrainData/TrainData/Traindata_with_Target.csv\"\n",
    "demographics_csv = \"./Data/archive/TrainData/TrainData/Train_Demographics.csv\"\n",
    "policy_csv = \"./Data/archive/TrainData/TrainData/Train_Policy.csv\"\n",
    "vehicle_csv = \"./Data/archive/TrainData/TrainData/Train_Vehicle.csv\"\n",
    "\n",
    "\n",
    "claims_df = pd.read_csv(claims_csv)\n",
    "customers_no_target_df = pd.read_csv(customers_withoutTarget_csv)\n",
    "customers_target_df = pd.read_csv(customers_withTarget_csv)\n",
    "demographics_df = pd.read_csv(demographics_csv)\n",
    "policy_df = pd.read_csv(policy_csv)\n",
    "vehicle_df = pd.read_csv(vehicle_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0083f7f9",
   "metadata": {},
   "source": [
    "### 3.1 Preparing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d7e58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2c9e93f",
   "metadata": {},
   "source": [
    "### 3.2 Removing Synonymous and Noisy Atrributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfbf6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bb6f42b",
   "metadata": {},
   "source": [
    "### 3.3 Dealing with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0e4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
